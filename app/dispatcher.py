import asyncio
from datetime import datetime
from typing import List

from telethon import TelegramClient, utils
from telethon.errors import FloodWaitError

from app.config import AppConfig as Config
from app.client import get_client
from app.parser import parse_message
from app.exporter import ExporterFactory
from app.checkpoint import CheckpointManager
from app.monitor import monitor
from app.logger import logger
from app.processor import MessageProcessor
from app.models import MessageData

class Dispatcher:
    """åˆ†å‘å™¨æ ¸å¿ƒï¼šåè°ƒå„ä¸ªç»„ä»¶å®Œæˆå·¥ä½œæµ"""

    def __init__(self):
        self.checkpoint = CheckpointManager()
        self.exporters = {} # {path: ExporterInstance}
        self.fieldnames = MessageData.get_csv_headers()

    async def run_cycle(self, client: TelegramClient = None):
        """ä¸»å¾ªç¯ï¼šåŠ è½½é…ç½® -> å‘ç°æº -> è¿­ä»£å¤„ç†"""
        if Config.load():
            logger.info("ğŸ”¥ é…ç½®å·²é‡è½½")
            self.exporters.clear()

        if not Config.tasks: return

        active_client = client or await get_client()
        monitor.update_stats(status="Processing", tasks_active=len(Config.tasks))
        
        try:
            # 1. å‘ç°éœ€è¦æ‰«æçš„æ‰€æœ‰å®ä½“
            entities = await self._discover_sources(active_client)
            monitor.update_stats(sources_active=len(entities))
            
            # 2. é¢„åˆå§‹åŒ–å¯¼å‡ºå™¨
            self._ensure_exporters()

            # 3. éå†å®ä½“è¿›è¡Œæ¶ˆæ¯æŠ“å–
            msg = f"ğŸ”„ å¼€å§‹åˆ†å‘å‘¨æœŸï¼Œæ‰«æ {len(entities)} ä¸ªæº"
            logger.info(msg) # MonitorLogHandler will pick this up
            for entity in entities:
                await self._sync_source(active_client, entity)

        finally:
            # é‡Šæ”¾èµ„æº
            for exp in self.exporters.values(): exp.close()
            self.exporters.clear()
            if not client: await active_client.disconnect()
            
            monitor.update_stats(
                status="Idle", 
                cycles_completed=monitor.stats["cycles_completed"] + 1,
                last_sync_time=datetime.now().strftime("%H:%M:%S")
            )

    async def _discover_sources(self, client):
        """å‘ç°æ‰€æœ‰ç›¸å…³æ•°æ®æº"""
        explicit_ids, has_all = set(), False
        for task in Config.tasks:
            if "all" in task.sources: has_all = True
            for s in task.sources:
                if isinstance(s, (int, str)) and str(s).lstrip('-').isdigit():
                    explicit_ids.add(int(s))
        
        entities = []
        if has_all:
            async for dialog in client.iter_dialogs():
                if dialog.is_group or dialog.is_channel:
                    entities.append(dialog.entity)
        else:
            for sid in explicit_ids:
                try: entities.append(await client.get_entity(sid))
                except Exception as e: logger.error(f"æ— æ³•è·å–æº {sid}: {e}")
        return entities

    def _ensure_exporters(self):
        """ç¡®ä¿æ‰€æœ‰ä»»åŠ¡çš„å¯¼å‡ºå™¨å·²å‡†å¤‡å°±ç»ª"""
        for task in Config.tasks:
            path = task.output.path
            if path not in self.exporters:
                exp = ExporterFactory.create(task.output.format, path, self.fieldnames)
                exp.open(mode='a')
                self.exporters[path] = exp

    async def _sync_source(self, client, entity):
        """åŒæ­¥å•ä¸ªæ•°æ®æº"""
        source_id = str(utils.get_peer_id(entity))
        group_title = getattr(entity, 'title', source_id)
        
        # åŒ¹é…å¯¹åº”æ­¤æºçš„æ‰€æœ‰ä»»åŠ¡
        matched_tasks = [t for t in Config.tasks if self._match_source(entity, t.sources)]
        if not matched_tasks: return

        last_id = self.checkpoint.get(source_id, 0)
        logger.info(f"ğŸ”„ æ‰«æ: [{group_title}] ä» ID: {last_id}")

        new_max_id = last_id
        current_source_processed = 0
        total_fetched = 0

        try:
            async for message in client.iter_messages(entity, min_id=last_id, reverse=True):
                if message.id <= last_id: continue
                total_fetched += 1
                
                # 1. æ ¸å¿ƒè§£æä¸å¢å¼º
                msg_data = await parse_message(message, group_title, source_id)
                msg_data = await MessageProcessor.process(msg_data)
                
                # 2. è·¯ç”±åˆ°ä»»åŠ¡
                was_routed = False
                for task in matched_tasks:
                    if MessageProcessor.is_match(task, msg_data):
                        if await self._export_to_task(task, msg_data):
                            was_routed = True
                
                if was_routed: 
                    current_source_processed += 1
                    monitor.increment("urls_identified")

                if message.id > new_max_id: new_max_id = message.id

            # 3. æ›´æ–°è¿›åº¦ä¸è®¡æ•°
            if new_max_id > last_id:
                self.checkpoint.set(source_id, new_max_id)
            
            monitor.increment("messages_processed", total_fetched)
            
            if current_source_processed > 0:
                msg = f"âœ… [{group_title}]: æ–°å¢ {current_source_processed} æ¡è®°å½•"
                logger.info(msg)
            elif total_fetched > 0:
                logger.info(f"â„¹ï¸ [{group_title}]: æ‰«æ {total_fetched} æ¡æ¶ˆæ¯ï¼Œæ— åŒ¹é…æˆ–å‡ä¸ºé‡å¤")

        except FloodWaitError as e:
            logger.warning(f"è§¦å‘é™æµï¼Œä¼‘çœ  {e.seconds} ç§’")
            await asyncio.sleep(e.seconds)
        except Exception as e:
            logger.error(f"åŒæ­¥ [{group_title}] å¤±è´¥: {e}")

    async def _export_to_task(self, task, msg: MessageData) -> bool:
        """æ‰§è¡Œå¯¼å‡ºä¸å»é‡æ£€æŸ¥"""
        exporter = self.exporters.get(task.output.path)
        if not exporter: return False
        
        if msg.url and exporter.is_duplicate(msg.url):
            msg_log = f"â­ï¸ è·³è¿‡é‡å¤ URL (ä»»åŠ¡: {task.name}, æº: {msg.source_group})"
            monitor.add_log(msg_log)
            return False

        exporter.write(msg.model_dump())
        return True

    def _match_source(self, entity, task_sources) -> bool:
        if "all" in task_sources: return True
        p_id, raw_id = str(utils.get_peer_id(entity)), str(entity.id)
        return any(str(s) in (p_id, raw_id) for s in task_sources)
